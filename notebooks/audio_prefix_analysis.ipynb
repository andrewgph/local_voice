{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import IPython.display as ipd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import incremental_transcriber\n",
    "from whisper_mlx.whisper_mlx import load_model as load_whisper_model\n",
    "from whisper_mlx.tokenizer import get_tokenizer\n",
    "\n",
    "whisper_model = load_whisper_model(\"../models/whisper\")\n",
    "\n",
    "tokenizer = get_tokenizer(\n",
    "    multilingual=whisper_model.is_multilingual,\n",
    "    num_languages=whisper_model.num_languages,\n",
    "    language=\"en\",\n",
    "    task=\"transcribe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_io import SAMPLE_RATE\n",
    "from min_rhasspy_piper.voice import PiperVoice\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "voice = PiperVoice.load(\n",
    "    model_path=\"../models/piper/voice.onnx\",\n",
    "    config_path=\"../models/piper/voice.json\")\n",
    "\n",
    "def generate_speech_prefix(text):\n",
    "    results = []\n",
    "    for result in voice.synthesize_stream_raw(text):\n",
    "        results.append(result)\n",
    "    speech_arr = np.concatenate(results)\n",
    "\n",
    "    # Make the sample rate used in audio_io\n",
    "    original_sr = voice.config.sample_rate\n",
    "    target_sr = SAMPLE_RATE\n",
    "    speech_arr = librosa.resample(speech_arr, orig_sr=original_sr, target_sr=target_sr)\n",
    "\n",
    "    # Add 2 seconds of silence to the end\n",
    "    speech_arr = np.append(speech_arr, np.zeros(int(target_sr * 2)))\n",
    "\n",
    "    return speech_arr\n",
    "\n",
    "def generate_audio_prefix(text):\n",
    "    speech_arr = generate_speech_prefix(text)\n",
    "    transcribe_result = incremental_transcriber.transcribe(speech_arr, whisper_model, tokenizer)\n",
    "\n",
    "    audio_prefix = {\n",
    "        \"result_logprob\": transcribe_result.logprob,\n",
    "        \"tokens\": transcribe_result.tokens,\n",
    "        \"np_arr\": transcribe_result.audio_arr\n",
    "    }\n",
    "\n",
    "    return audio_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_audio_prefix = generate_audio_prefix(\"Hello, I am a voice assistant that can help you with your questions. How can I help you today?\")\n",
    "ipd.display(ipd.Audio(synthetic_audio_prefix[\"np_arr\"], rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_audio_prefix = {}\n",
    "with open(\"../calibration/audio_prefix.json\", \"r\") as f:\n",
    "    serializable_dict = json.load(f)\n",
    "    recorded_audio_prefix = {k: np.array(v) for k, v in serializable_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.display(ipd.Audio(recorded_audio_prefix[\"np_arr\"], rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_utterance_to_audio_arr = {}\n",
    "with open(\"short_utterances_audio_trimmed.json\", \"r\") as f:\n",
    "    serializable_dict = json.load(f)\n",
    "    trimmed_utterance_to_audio_arr = {k: np.array(v) for k, v in serializable_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.display(ipd.Audio(trimmed_utterance_to_audio_arr[\"Okay\"], rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "wer = evaluate.load(\"wer\")\n",
    "\n",
    "def evaluate_prefix(audio_prefix):\n",
    "    utterances = []\n",
    "    predictions = []\n",
    "    trimmed_utterances = []\n",
    "    trimmed_results = []\n",
    "\n",
    "    for utterance, audio_arr in trimmed_utterance_to_audio_arr.items():\n",
    "        result = incremental_transcriber.transcribe(audio_arr, whisper_model, tokenizer, audio_prefix)\n",
    "        print(utterance, \"->\", result.text)\n",
    "\n",
    "        utterances.append(utterance)\n",
    "        predictions.append(result.text)\n",
    "\n",
    "        trimmed_result = ''.join(c for c in result.text.strip() if c.isalnum() or c.isspace())\n",
    "        trimmed_utterance = ''.join(c for c in utterance.strip() if c.isalnum() or c.isspace())\n",
    "\n",
    "        trimmed_utterances.append(trimmed_utterance)\n",
    "        trimmed_results.append(trimmed_result)\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"WER:                      {wer.compute(references=utterances, predictions=predictions):.4f}\")\n",
    "    print(f\"WER (remove punctuation): {wer.compute(references=trimmed_utterances, predictions=trimmed_results):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_prefix(audio_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_prefix(audio_prefix=synthetic_audio_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_prefix(audio_prefix=recorded_audio_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_noise_profile(clean_audio, noise_profile, noise_factor=0.1):\n",
    "    # Normalize clean_audio and noise_profile\n",
    "    clean_audio_norm = clean_audio / np.max(np.abs(clean_audio))\n",
    "    noise_profile_norm = noise_profile / np.max(np.abs(noise_profile))\n",
    "    \n",
    "    # Tile the normalized noise profile to match the length of the clean audio\n",
    "    tiled_noise = np.tile(noise_profile_norm, (len(clean_audio_norm) // len(noise_profile_norm)) + 1)[:len(clean_audio_norm)]\n",
    "    \n",
    "    # Mix the normalized noise with the normalized clean audio\n",
    "    noisy_audio = clean_audio_norm + noise_factor * tiled_noise\n",
    "    \n",
    "    # Rescale the mixed audio to the original range of clean_audio\n",
    "    max_amplitude = np.max(np.abs(clean_audio))\n",
    "    noisy_audio_rescaled = noisy_audio * max_amplitude / np.max(np.abs(noisy_audio))\n",
    "    \n",
    "    return noisy_audio_rescaled\n",
    "\n",
    "def generate_noisy_audio_prefix(text, noise_profile, noise_factor):\n",
    "    speech_arr = generate_speech_prefix(text)\n",
    "    noisy_speech_arr = apply_noise_profile(speech_arr, noise_profile, noise_factor)\n",
    "    transcribe_result = incremental_transcriber.transcribe(noisy_speech_arr, whisper_model, tokenizer)\n",
    "\n",
    "    print(\"Said: \", text)\n",
    "    print(\"Heard: \", transcribe_result.text)\n",
    "\n",
    "    audio_prefix = {\n",
    "        \"result_logprob\": transcribe_result.logprob,\n",
    "        \"tokens\": transcribe_result.tokens,\n",
    "        \"np_arr\": transcribe_result.audio_arr\n",
    "    }\n",
    "\n",
    "    return audio_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get noise sample from recorded audio\n",
    "noise_profile = recorded_audio_prefix['np_arr'][:SAMPLE_RATE // 2]\n",
    "ipd.display(ipd.Audio(noise_profile, rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_audio_prefix = generate_noisy_audio_prefix(\"Hello, how can I help you today?\", noise_profile, noise_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.display(ipd.Audio(noisy_audio_prefix['np_arr'], rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_prefix(audio_prefix=noisy_audio_prefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple_voice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
