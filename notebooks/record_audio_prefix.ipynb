{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import incremental_transcriber\n",
    "from whisper_mlx.whisper_mlx import load_model as load_whisper_model\n",
    "from whisper_mlx.tokenizer import get_tokenizer\n",
    "\n",
    "whisper_model = load_whisper_model(\"../models/whisper\")\n",
    "\n",
    "tokenizer = get_tokenizer(\n",
    "    multilingual=whisper_model.is_multilingual,\n",
    "    num_languages=whisper_model.num_languages,\n",
    "    language=\"en\",\n",
    "    task=\"transcribe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "for i in range(p.get_device_count()):\n",
    "    info = p.get_device_info_by_index(i)\n",
    "    print(f\"Device {i}: {info['name']} (Input Channels: {info['maxInputChannels']})\")\n",
    "\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import pyaudio\n",
    "\n",
    "DEVICE_IDX = 3\n",
    "\n",
    "def audio_bytes_to_np_array(bytes_data):\n",
    "    arr = np.frombuffer(bytes_data, dtype='<i2')\n",
    "    arr = arr.astype('float32') / 32768.0\n",
    "    return arr\n",
    "\n",
    "def record_audio(text, min_seconds=2, max_seconds=8):\n",
    "    num_words = len(text.split())\n",
    "    num_seconds = num_words * 0.4 # 400ms per word\n",
    "    num_seconds = ceil(max(min(num_seconds, max_seconds), min_seconds))\n",
    "\n",
    "    # Parameters\n",
    "    FORMAT = pyaudio.paInt16  # Audio format\n",
    "    CHANNELS = 1  # Number of audio channels\n",
    "    RATE = 16000  # Sample rate\n",
    "    CHUNK = 160  # Frame size\n",
    "    RECORD_SECONDS = num_seconds  # Duration to record\n",
    "\n",
    "    # Initialize pyaudio\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Open stream\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        input_device_index=DEVICE_IDX, \n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(f\"Recording for {RECORD_SECONDS} seconds...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    # Record for the set duration\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    # Terminate the PortAudio interface\n",
    "    audio.terminate()\n",
    "\n",
    "    # Combine all the frames as a single byte string\n",
    "    recorded_bytes = b''.join(frames)\n",
    "    return recorded_bytes\n",
    "\n",
    "def record_audio_prefix(text, num_seconds=10):\n",
    "    print(\"Say: \", text)\n",
    "    audio_bytes = record_audio(text, min_seconds=num_seconds, max_seconds=num_seconds)\n",
    "    speech_arr = audio_bytes_to_np_array(audio_bytes)\n",
    "\n",
    "    tokens = tokenizer.encode(text)\n",
    "\n",
    "    transcribe_result = incremental_transcriber.transcribe(speech_arr, whisper_model, tokenizer)\n",
    "    print(\"Heard: \", transcribe_result.text)\n",
    "\n",
    "    audio_prefix = {\n",
    "        \"result_logprob\": 0.0,\n",
    "        \"tokens\": tokens,\n",
    "        \"np_arr\": speech_arr\n",
    "    }\n",
    "\n",
    "    return audio_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_audio_prefix = record_audio_prefix(\"Hello, how can I help you today? Hi, what is the capital of France? The capital of France is Paris.\", num_seconds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.display(ipd.Audio(recorded_audio_prefix[\"np_arr\"], rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"audio_prefix.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    # Convert numpy array to list for JSON serialization\n",
    "    audio_prefix_copy = recorded_audio_prefix.copy()\n",
    "    audio_prefix_copy['np_arr'] = recorded_audio_prefix['np_arr'].tolist()\n",
    "    json.dump(audio_prefix_copy, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple_voice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
